import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from PIL import Image, ImageEnhance, ImageOps, ImageFilter
import matplotlib.pyplot as plt
import random
import config
import os
from model import CaptchaModel, device

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams["font.family"] = []

class CaptchaDataset(Dataset):
    def __init__(self, max_samples=None):  # é»˜è®¤ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ ·æœ¬
        self.image_width, self.image_height = config.IMAGE_SIZE
        self.charset_size = len(config.CHARSET)
        self.char_to_index = {char: i for i, char in enumerate(config.CHARSET)}
        self.index_to_char = {i: char for i, char in enumerate(config.CHARSET)}
        
        # åŠ è½½æ•°æ®
        self.images = []
        self.labels = []
        
        # è·å–æ‰€æœ‰éªŒè¯ç å›¾ç‰‡æ–‡ä»¶
        file_list = [f for f in os.listdir(config.OUTPUT_DIR) if f.endswith('.png')]
        # é™åˆ¶æ ·æœ¬æ•°é‡ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if max_samples is not None:
            file_list = file_list[:max_samples]
        random.shuffle(file_list)
        
        for filename in file_list:
            try:
                # ä»æ–‡ä»¶åä¸­æå–éªŒè¯ç æ–‡æœ¬
                captcha_text = filename.split('.')[0]
                # ç¡®ä¿éªŒè¯ç é•¿åº¦ä¸è¶…è¿‡æœ€å¤§é•¿åº¦
                if len(captcha_text) > config.CODE_MAX_LENGTH:
                    continue

                # æ‰“å¼€å›¾ç‰‡å¹¶è½¬ä¸ºç°åº¦
                image_path = os.path.join(config.OUTPUT_DIR, filename)
                image = Image.open(image_path).convert('L')
                # è°ƒæ•´å¤§å°
                image = image.resize((self.image_width, self.image_height))
                
                # æ•°æ®å¢å¼º
                # éšæœºæ—‹è½¬ (-5, 5) åº¦ (å‡å°æ—‹è½¬èŒƒå›´)
                if random.random() > 0.5:
                    angle = random.uniform(-5, 5)
                    image = image.rotate(angle, expand=False, fillcolor=255)
                
                # éšæœºå¹³ç§» (å‡å°å¹³ç§»èŒƒå›´)
                if random.random() > 0.5:
                    dx = random.randint(-3, 3)
                    dy = random.randint(-3, 3)
                    from PIL import ImageChops
                    image = ImageChops.offset(image, dx, dy)
                    # å¡«å……å¹³ç§»åçš„ç©ºç™½åŒºåŸŸä¸ºç™½è‰²
                    image = ImageOps.expand(image, border=3, fill=255)
                    image = image.resize((self.image_width, self.image_height))
                
                # éšæœºç¼©æ”¾ (å‡å°ç¼©æ”¾èŒƒå›´)
                if random.random() > 0.5:
                    scale = random.uniform(0.9, 1.1)
                    new_width = int(self.image_width * scale)
                    new_height = int(self.image_height * scale)
                    image = image.resize((new_width, new_height))
                    # è£å‰ªæˆ–å¡«å……åˆ°åŸå§‹å¤§å°
                    if new_width > self.image_width or new_height > self.image_height:
                        left = max(0, (new_width - self.image_width) // 2)
                        top = max(0, (new_height - self.image_height) // 2)
                        right = min(new_width, left + self.image_width)
                        bottom = min(new_height, top + self.image_height)
                        image = image.crop((left, top, right, bottom))
                    else:
                        image = ImageOps.expand(image, border=((self.image_width - new_width) // 2,
                                                              (self.image_height - new_height) // 2),
                                                fill=255)
                    image = image.resize((self.image_width, self.image_height))
                
                # éšæœºå¯¹æ¯”åº¦è°ƒæ•´
                if random.random() > 0.5:
                    enhancer = ImageEnhance.Contrast(image)
                    factor = random.uniform(0.8, 1.5)
                    image = enhancer.enhance(factor)
                
                # éšæœºäº®åº¦è°ƒæ•´
                if random.random() > 0.5:
                    enhancer = ImageEnhance.Brightness(image)
                    factor = random.uniform(0.8, 1.2)
                    image = enhancer.enhance(factor)
                
                # éšæœºæ·»åŠ å™ªå£°
                if random.random() > 0.5:
                    noise_level = random.uniform(0.01, 0.05)
                    image_array = np.array(image)
                    noise = np.random.normal(0, 255 * noise_level, image_array.shape)
                    noisy_image = np.clip(image_array + noise, 0, 255).astype(np.uint8)
                    image = Image.fromarray(noisy_image)
                
                # è½¬ä¸ºæ•°ç»„å¹¶å½’ä¸€åŒ–
                image_array = np.array(image) / 255.0
                # è°ƒæ•´ç»´åº¦ä¸º (1, height, width) ä»¥åŒ¹é… PyTorch çš„è¾“å…¥æ ¼å¼
                image_array = np.expand_dims(image_array, axis=0)

                # å¤„ç†æ ‡ç­¾
                label = np.zeros((config.CODE_MAX_LENGTH, self.charset_size))
                for i, char in enumerate(captcha_text):
                    if char in self.char_to_index:
                        label[i, self.char_to_index[char]] = 1
                # å¯¹äºé•¿åº¦ä¸è¶³6çš„éªŒè¯ç ï¼Œå…¶ä½™ä½ç½®å¡«å……0

                self.images.append(image_array)
                self.labels.append(label)
            except Exception as e:
                print(f"Error loading {filename}: {e}")
                continue

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = torch.tensor(self.images[idx], dtype=torch.float32)
        label = torch.tensor(self.labels[idx], dtype=torch.float32)
        return image, label

class CaptchaTrainer:
    def __init__(self):
        self.model = CaptchaModel().to(device)
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.AdamW(self.model.parameters(), lr=0.0005, weight_decay=1e-4)
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='max', factor=0.5, patience=5)
        self.char_to_index = {char: i for i, char in enumerate(config.CHARSET)}
        self.index_to_char = {i: char for i, char in enumerate(config.CHARSET)}
        self.best_val_acc = 0.0

    def train(self, epochs=10, batch_size=16, validation_split=0.2):
        """è®­ç»ƒæ¨¡å‹"""
        # åŠ è½½æ•°æ®ï¼ˆä½¿ç”¨æ‰€æœ‰ç”Ÿæˆçš„éªŒè¯ç ï¼‰
        dataset = CaptchaDataset(max_samples=None)
        # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        train_size = int(len(dataset) * (1 - validation_split))
        val_size = len(dataset) - train_size
        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
        # è°ƒæ•´å·¥ä½œè¿›ç¨‹æ•°
        train_num_workers =config.TRAIN_NUM_WORKERS
        val_num_workers = config.VAL_NUM_WORKERS
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        print(f"ğŸ”„ åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨: æ‰¹æ¬¡å¤§å°={batch_size}, å·¥ä½œè¿›ç¨‹æ•°={train_num_workers}")
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=train_num_workers)
        print(f"âœ… è®­ç»ƒæ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")
        
        print(f"ğŸ”„ åˆ›å»ºéªŒè¯æ•°æ®åŠ è½½å™¨: æ‰¹æ¬¡å¤§å°={batch_size}, å·¥ä½œè¿›ç¨‹æ•°={val_num_workers}")
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=val_num_workers)
        print(f"âœ… éªŒè¯æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")

        print(f"ğŸš€ è®­ç»ƒå¼€å§‹: å…±{epochs}ä¸ªepoch, æ‰¹å¤§å°{batch_size}", flush=True)
        print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯: è®­ç»ƒé›†å¤§å°={len(train_dataset)}, éªŒè¯é›†å¤§å°={len(val_dataset)}", flush=True)

        # è®­ç»ƒå†å²
        history = {
            'accuracy': [],
            'val_accuracy': [],
            'loss': [],
            'val_loss': []
        }

        for epoch in range(epochs):
            # å½“å‰è®­ç»ƒè½®æ¬¡ï¼ˆä»1å¼€å§‹ï¼‰
            current_epoch = epoch + 1
            # è®­ç»ƒé˜¶æ®µ
            self.model.train()
            train_correct = 0
            train_total = 0
            train_loss = 0

            total_batches = len(train_loader)
            # è®¡ç®—æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹çš„æ€»æ‰¹æ¬¡æ•°
            total_training_batches = epochs * total_batches
            for batch_idx, (images, labels) in enumerate(train_loader):
                # æ‰“å°batchè¿›åº¦
                # æ¯10ä¸ªæ‰¹æ¬¡æ‰“å°ä¸€æ¬¡æ‰¹æ¬¡è¿›åº¦
                if batch_idx % 10 == 0:
                    # è®¡ç®—å½“å‰å·²å®Œæˆçš„å…¨å±€æ‰¹æ¬¡æ•°
                    completed_batches = epoch * total_batches + batch_idx
                    print(f"ğŸ”„ è®­ç»ƒè¿›åº¦: ç¬¬ {current_epoch}/{epochs} è½®, æ‰¹æ¬¡ {batch_idx}/{total_batches} (å…¨å±€: {completed_batches}/{total_training_batches})", flush=True)
                images = images.to(device)
                labels = labels.to(device)

                # å‰å‘ä¼ æ’­
                outputs = self.model(images)
                # è®¡ç®—æŸå¤±
                loss = 0
                for i in range(config.CODE_MAX_LENGTH):
                    loss += self.criterion(outputs[:, i, :], torch.argmax(labels[:, i, :], dim=1))
                # åå‘ä¼ æ’­å’Œä¼˜åŒ–
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

                # æ‰“å°æ¯å¼ å›¾ç‰‡çš„è¯¦ç»†é¢„æµ‹ç»“æœ
                train_loss += loss.item()
                batch_correct = 0
                batch_total = 0

                # æ¯10ä¸ªæ‰¹æ¬¡æ‰“å°ä¸€æ¬¡è¯¦ç»†é¢„æµ‹ç»“æœ
                if batch_idx % 10 == 0:
                    print(f"ğŸ“Š ç¬¬ {current_epoch} è½® æ‰¹æ¬¡ {batch_idx} æŸå¤±: {loss.item():.4f}")
                    # æ‰“å°å‰3å¼ å›¾ç‰‡çš„è¯¦ç»†é¢„æµ‹ç»“æœ
                    print_idx = 0

                for img_idx in range(labels.size(0)):
                    img_correct = True
                    predicted_code = []
                    true_code = []
                    char_details = []

                    for i in range(config.CODE_MAX_LENGTH):
                        _, predicted = torch.max(outputs[img_idx, i, :], 0)
                        true_label = torch.argmax(labels[img_idx, i, :], 0)
                        predicted_code.append(str(predicted.item()))
                        true_code.append(str(true_label.item()))

                        char_status = 'âœ“' if predicted == true_label else 'âœ—'
                        char_details.append(f"å­—ç¬¦{i+1}: é¢„æµ‹={predicted.item()}, çœŸå®={true_label.item()}, {char_status}")

                        if predicted != true_label:
                            img_correct = False

                    # åªç»Ÿè®¡å®Œå…¨æ­£ç¡®çš„éªŒè¯ç 
                    if img_correct:
                        batch_correct += 1
                    batch_total += 1

                    # æ¯10ä¸ªæ‰¹æ¬¡æ‰“å°å‰3å¼ å›¾ç‰‡çš„è¯¦ç»†ç»“æœ
                    if batch_idx % 10 == 0 and print_idx < 3:
                        print(f"ğŸ” ç¬¬ {current_epoch} è½® æ‰¹æ¬¡ {batch_idx} - æ ·æœ¬ {img_idx} é¢„æµ‹è¯¦æƒ…:")
                        print(f"   é¢„æµ‹åºåˆ—: {' '.join(predicted_code)}")
                        print(f"   çœŸå®åºåˆ—: {' '.join(true_code)}")
                        print(f"   ç»“æœ: {'âœ… æ­£ç¡®' if img_correct else 'âŒ é”™è¯¯'}")
                        for detail in char_details:
                            print(f"   {detail}")
                        print_idx += 1

                train_correct += batch_correct
                train_total += batch_total

            # è®¡ç®—è®­ç»ƒå‡†ç¡®ç‡å’Œå¹³å‡æŸå¤±
            train_acc = train_correct / train_total
            train_avg_loss = train_loss / len(train_loader)
            history['accuracy'].append(train_acc)
            history['loss'].append(train_avg_loss)

            print(f"ğŸ“ˆ è®­ç»ƒç»“æœ: å‡†ç¡®ç‡={train_acc:.4f}, æŸå¤±={train_avg_loss:.4f}", flush=True)

            # éªŒè¯é˜¶æ®µ
            val_correct = 0
            val_total = 0
            val_loss = 0

            self.model.eval()
            with torch.no_grad():
                for images, labels in val_loader:
                    images = images.to(device)
                    labels = labels.to(device)

                    outputs = self.model(images)
                    loss = 0
                    for i in range(config.CODE_MAX_LENGTH):
                        loss += self.criterion(outputs[:, i, :], torch.argmax(labels[:, i, :], dim=1))

                    val_loss += loss.item()

                    for img_idx in range(labels.size(0)):
                        img_correct = True
                        for i in range(config.CODE_MAX_LENGTH):
                            _, predicted = torch.max(outputs[img_idx, i, :], 0)
                            true_label = torch.argmax(labels[img_idx, i, :], 0)
                            if predicted != true_label:
                                img_correct = False
                                break

                        if img_correct:
                            val_correct += 1
                        val_total += 1

            val_acc = val_correct / val_total
            val_avg_loss = val_loss / len(val_loader)
            history['val_accuracy'].append(val_acc)
            history['val_loss'].append(val_avg_loss)

            print(f"ğŸ” éªŒè¯ç»“æœ: å‡†ç¡®ç‡={val_acc:.4f}, æŸå¤±={val_avg_loss:.4f}", flush=True)

            # è°ƒæ•´å­¦ä¹ ç‡
            self.scheduler.step(val_acc)

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > self.best_val_acc:
                self.best_val_acc = val_acc
                print(f"ğŸ’¾ å½“å‰æ¨¡å‹æ˜¯æˆåŠŸçš„æ¨¡å‹: (å‡†ç¡®ç‡è¾¾åˆ°={val_acc:.4f})")

        torch.save(self.model.state_dict(), config.PY_MODEL_FILE)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {config.PY_MODEL_FILE}")
        # ç»˜åˆ¶è®­ç»ƒå†å²
        self.plot_history(history)
        # ä¿å­˜è®­ç»ƒå†å²
        np.save(config.PY_MODEL_HISTORY_DATA, history)
        print(f"âœ… è®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.best_val_acc:.4f}")
        return history


    def plot_history(self, history):
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        plt.figure(figsize=(12, 4))

        # ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿
        plt.subplot(1, 2, 1)
        plt.plot(history['accuracy'], label='è®­ç»ƒå‡†ç¡®ç‡')
        plt.plot(history['val_accuracy'], label='éªŒè¯å‡†ç¡®ç‡')
        plt.title('å‡†ç¡®ç‡æ›²çº¿')
        plt.xlabel('epoch')
        plt.ylabel('å‡†ç¡®ç‡')
        plt.legend()

        # ç»˜åˆ¶æŸå¤±æ›²çº¿
        plt.subplot(1, 2, 2)
        plt.plot(history['loss'], label='è®­ç»ƒæŸå¤±')
        plt.plot(history['val_loss'], label='éªŒè¯æŸå¤±')
        plt.title('æŸå¤±æ›²çº¿')
        plt.xlabel('epoch')
        plt.ylabel('æŸå¤±')
        plt.legend()

        plt.tight_layout()
        plt.savefig(config.PY_MODEL_HISTORY)
        print(f"ğŸ“Š è®­ç»ƒå†å²å›¾è¡¨å·²ä¿å­˜ä¸º {config.PY_MODEL_HISTORY}")

if __name__ == "__main__":
    trainer = CaptchaTrainer()
    trainer.train(epochs=config.TRAIN_EPOCHS, batch_size=config.TRAIN_BATCH_SIZE)